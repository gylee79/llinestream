/**
 * @fileoverview Video Analysis with Gemini & Transcoder API using Firebase Cloud Functions v2.
 * Gemini Model: gemini-2.5-flash
 * Transcoder API for HLS Packaging with AES-128 encryption.
 */
import { setGlobalOptions } from "firebase-functions/v2";
import { onDocumentWritten, onDocumentDeleted } from "firebase-functions/v2/firestore";
import * as admin from "firebase-admin";
import { GoogleGenerativeAI, SchemaType } from "@google/generative-ai";
import { GoogleAIFileManager, FileState } from "@google/generative-ai/server";
import { TranscoderServiceClient } from '@google-cloud/video-transcoder';
import * as path from "path";
import * as os from "os";
import * as fs from "fs";
import * as crypto from "crypto";

// 0. Firebase Admin & Global Options ì´ˆê¸°í™”
if (!admin.apps.length) {
  admin.initializeApp();
}

setGlobalOptions({
  region: "us-central1",
  secrets: ["GOOGLE_GENAI_API_KEY"],
  timeoutSeconds: 540, // Set to maximum allowed timeout (9 minutes)
  memory: "2GiB",
  serviceAccount: "firebase-adminsdk@studio-6929130257-b96ff.iam.gserviceaccount.com",
});

const db = admin.firestore();
const storage = admin.storage();
const bucket = storage.bucket();


// 1. MIME Type ë„ìš°ë¯¸
function getMimeType(filePath: string): string {
  const extension = path.extname(filePath).toLowerCase();
  switch (extension) {
    case ".mp4": return "video/mp4";
    case ".mov": return "video/quicktime";
    case ".avi": return "video/x-msvideo";
    case ".wmv": return "video/x-ms-wmv";
    case ".webm": return "video/webm";
    case ".mkv": return "video/x-matroska";
    default: return "video/mp4";
  }
}

// 2. ì§€ì—° ì´ˆê¸°í™” (Lazy Initialization)
let genAI: GoogleGenerativeAI | null = null;
let fileManager: GoogleAIFileManager | null = null;
let transcoderClient: TranscoderServiceClient | null = null;

function initializeTools() {
  const apiKey = process.env.GOOGLE_GENAI_API_KEY;
  if (!apiKey) throw new Error("GOOGLE_GENAI_API_KEY is missing!");

  if (!genAI) genAI = new GoogleGenerativeAI(apiKey);
  if (!fileManager) fileManager = new GoogleAIFileManager(apiKey);
  if (!transcoderClient) transcoderClient = new TranscoderServiceClient();
  
  return { genAI, fileManager, transcoderClient };
}


// 3. HLS Packaging with Transcoder API (AES-128)
async function createHlsPackagingJob(episodeId: string, inputUri: string, docRef: admin.firestore.DocumentReference): Promise<void> {
    try {
        await docRef.update({ packagingStatus: "processing", packagingError: null });
        console.log(`[${episodeId}] HLS Job: Set status to 'processing'.`);

        const { transcoderClient: client } = initializeTools();
        const projectId = await client.getProjectId();
        const location = 'us-central1';

        const outputFolder = `episodes/${episodeId}/packaged/`;
        const outputUri = `gs://${bucket.name}/${outputFolder}`;

        // [1ë‹¨ê³„: í‚¤ ìƒì„±]
        const aesKey = crypto.randomBytes(16);
        const keyFileName = 'enc.key';
        const keyStoragePath = `episodes/${episodeId}/keys/${keyFileName}`;
        const keyFile = bucket.file(keyStoragePath);
        
        // [2ë‹¨ê³„: í‚¤ ë³´ê´€]
        console.log(`[${episodeId}] HLS Job: Uploading AES-128 key to ${keyStoragePath}`);
        await keyFile.save(aesKey, { contentType: 'application/octet-stream' });
        
        const keyStorageUriForManifest = `gs://${bucket.name}/${keyStoragePath}`;
        
        const signedUrlExpireTime = Date.now() + 7 * 24 * 60 * 60 * 1000; // 7 days validity
        const [signedKeyUrl] = await keyFile.getSignedUrl({ action: 'read', expires: signedUrlExpireTime });
        console.log(`[${episodeId}] HLS Job: Generated Signed URL for key.`);

        // [3ë‹¨ê³„: ì‘ì—… ì§€ì‹œì„œ ì‘ì„±]
        const request = {
            parent: `projects/${projectId}/locations/${location}`,
            job: {
                inputUri,
                outputUri,
                config: {
                    // [í¬ì¥: ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ë¶„ë¦¬ ë‹´ê¸°]
                    muxStreams: [
                        {
                            key: 'video-sd-fmp4',
                            container: 'fmp4',
                            elementaryStreams: ['sd-video-stream'],
                            segmentSettings: { individualSegments: true, segmentDuration: { seconds: 4 } },
                            encryptionId: 'aes-128-encryption',
                        },
                        {
                            key: 'audio-fmp4',
                            container: 'fmp4',
                            elementaryStreams: ['audio-stream'],
                            segmentSettings: { individualSegments: true, segmentDuration: { seconds: 4 } },
                            encryptionId: 'aes-128-encryption',
                        }
                    ],
                    // [ì¬ë£Œ: í•´ìƒë„ ë° GOP ì„¤ì •]
                    elementaryStreams: [
                        { key: 'sd-video-stream', videoStream: { h264: { 
                            heightPixels: 480, 
                            widthPixels: 854, 
                            bitrateBps: 1000000, 
                            frameRate: 30,
                            gopDuration: { seconds: 2 } // ìˆ˜í•™ì  ì •ë ¬ (4ì´ˆ / 2ì´ˆ = ì •ìˆ˜)
                        }}},
                        { key: 'audio-stream', audioStream: { codec: 'aac', bitrateBps: 128000 } },
                    ],
                    // [ìµœì¢… ëª©ë¡: HLS ë§ˆìŠ¤í„° íŒŒì¼]
                    manifests: [{ fileName: 'manifest.m3u8', type: 'HLS' as const, muxStreams: ['video-sd-fmp4', 'audio-fmp4'] }],
                    // [ìë¬¼ì‡ : AES-128 + ClearKey + CENC ëª¨ë“œ]
                    encryptions: [{ 
                        id: 'aes-128-encryption', 
                        aes128: { uri: keyStorageUriForManifest },
                        drmSystems: {
                            clearkey: {}
                        },
                        // âœ… ì´ë²ˆ ì—ëŸ¬ì˜ í•µì‹¬ í•´ê²°ì±…: fmp4ë¥¼ ìœ„í•œ ì•”í˜¸í™” ëª¨ë“œ ì„¤ì •
                        encryptionMode: 'cenc' 
                    }],
                },
            },
        };
        
        console.log(`[${episodeId}] HLS Job: Creating Transcoder job...`);
        const [createJobResponse] = await client.createJob(request);
        
        if (!createJobResponse.name) {
            throw new Error('Transcoder job creation failed, no job name returned.');
        }
        const jobName = createJobResponse.name;
        console.log(`[${episodeId}] HLS Job Created: ${jobName}`);

        const POLLING_INTERVAL = 15000; // 15 seconds
        const MAX_POLLS = 35; // 35 * 15s = 525s
        let jobSucceeded = false;

        for (let i = 0; i < MAX_POLLS; i++) {
            await new Promise(resolve => setTimeout(resolve, POLLING_INTERVAL));
            const [job] = await client.getJob({ name: jobName });
            console.log(`[${episodeId}] Polling status: ${job.state}`);

            if (job.state === 'SUCCEEDED') {
                await docRef.update({
                    packagingStatus: 'completed',
                    manifestUrl: `${outputUri}manifest.m3u8`.replace(`gs://${bucket.name}/`, `https://storage.googleapis.com/${bucket.name}/`),
                    keyServerUrl: signedKeyUrl,
                    packagingError: null,
                });
                jobSucceeded = true;
                break;
            } else if (job.state === 'FAILED') {
                throw new Error(`Transcoder job failed: ${JSON.stringify(job.error, null, 2)}`);
            }
        }

        if (!jobSucceeded) throw new Error('Transcoder job timed out.');

    } catch (error: any) {
        console.error(`[${episodeId}] Packaging Critical Error:`, error);
        await docRef.update({ 
            packagingStatus: "failed", 
            packagingError: error.message || 'An unknown error occurred during HLS packaging.' 
        });
    }
}

// ==========================================
// [Trigger] ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ (v2 onDocumentWritten)
// ==========================================
export const analyzeVideoOnWrite = onDocumentWritten("episodes/{episodeId}", async (event) => {
    const change = event.data;
    if (!change) return;

    if (!change.after.exists) {
      console.log(`[${event.params.episodeId}] Document deleted, skipping.`);
      return;
    }
    
    const afterData = change.after.data() as EpisodeData;
    const beforeData = change.before.exists ? change.before.data() as EpisodeData : null;

    if (afterData.aiProcessingStatus !== 'pending' || (beforeData && beforeData.aiProcessingStatus === afterData.aiProcessingStatus)) {
      return;
    }

    const { episodeId } = event.params;
    const docRef = change.after.ref;
    
    console.log(`âœ¨ [${episodeId}] New analysis job detected. Starting...`);

    await docRef.update({ aiProcessingStatus: "processing" });
    
    const filePath = afterData.filePath;
    if (!filePath) {
      await docRef.update({ 
          aiProcessingStatus: "failed", 
          packagingStatus: "failed", 
          aiProcessingError: "No filePath found in document.",
          packagingError: "No filePath found in document."
      });
      return;
    }
    const inputUriForTranscoder = `gs://${bucket.name}/${filePath}`;
    
    const aiAnalysisPromise = runAiAnalysis(episodeId, filePath, docRef);
    const hlsPackagingPromise = createHlsPackagingJob(episodeId, inputUriForTranscoder, docRef);

    try {
        await Promise.allSettled([aiAnalysisPromise, hlsPackagingPromise]);
        console.log(`âœ… [${episodeId}] All jobs (AI & HLS) have finished their execution.`);
    } catch(error: any) {
        console.error(`âŒ [${episodeId}] A critical unexpected error occurred in Promise.all. This should not happen.`, error);
    }
});

async function runAiAnalysis(episodeId: string, filePath: string, docRef: admin.firestore.DocumentReference) {
    const modelName = "gemini-2.5-flash";
    console.log(`ğŸš€ [${episodeId}] AI Processing started (Target: ${modelName}).`);
    
    const { genAI: localGenAI, fileManager: localFileManager } = initializeTools();
    const tempFilePath = path.join(os.tmpdir(), path.basename(filePath));
    let uploadedFile: any = null;

    try {
      await bucket.file(filePath).download({ destination: tempFilePath });
      
      const uploadResponse = await localFileManager.uploadFile(tempFilePath, {
        mimeType: getMimeType(filePath),
        displayName: episodeId,
      });
      uploadedFile = uploadResponse.file;
      console.log(`[${episodeId}] Uploaded to Google AI: ${uploadedFile.uri}`);

      let state = uploadedFile.state;
      while (state === FileState.PROCESSING) {
        await new Promise((resolve) => setTimeout(resolve, 5000));
        const freshFile = await localFileManager.getFile(uploadedFile.name);
        state = freshFile.state;
        console.log(`... AI processing status: ${state}`);
      }

      if (state === FileState.FAILED) throw new Error("Google AI file processing failed.");

      console.log(`[${episodeId}] Calling Gemini model...`);
      
      const model = localGenAI.getGenerativeModel({ 
        model: modelName, 
        generationConfig: {
          responseMimeType: "application/json",
          responseSchema: {
            type: SchemaType.OBJECT,
            properties: {
              transcript: { type: SchemaType.STRING, description: "ì˜ìƒì˜ ì „ì²´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ ëŒ€ë³¸ì…ë‹ˆë‹¤. ì˜ìƒì´ ì˜ì–´ë¼ë„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”." },
              summary: { type: SchemaType.STRING, description: "ì˜ìƒ ì „ì²´ ë‚´ìš©ì— ëŒ€í•œ ìƒì„¸í•˜ê³  êµ¬ì¡°í™”ëœ í•œêµ­ì–´ ìš”ì•½ë¬¸ì…ë‹ˆë‹¤." },
              timeline: {
                type: SchemaType.ARRAY,
                description: "ì‹œê°„ëŒ€ë³„ ì£¼ìš” ì´ë²¤íŠ¸ ë° í™”ë©´ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤.",
                items: {
                  type: SchemaType.OBJECT,
                  properties: {
                    startTime: { type: SchemaType.STRING, description: "ì´ë²¤íŠ¸ ì‹œì‘ ì‹œê°„. ë°˜ë“œì‹œ HH:MM:SS.mmm í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤." },
                    endTime: { type: SchemaType.STRING, description: "ì´ë²¤íŠ¸ ì¢…ë£Œ ì‹œê°„. ë°˜ë“œì‹œ HH:MM:SS.mmm í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤." },
                    subtitle: { type: SchemaType.STRING, description: "í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í•µì‹¬ ëŒ€ì‚¬ ë˜ëŠ” ìë§‰ì…ë‹ˆë‹¤. (í•œêµ­ì–´)" },
                    description: { type: SchemaType.STRING, description: "í•´ë‹¹ ì‹œê°„ëŒ€ì— í™”ë©´ì— ë‚˜íƒ€ë‚˜ëŠ” ì‹œê°ì  ìš”ì†Œ(ì¸ë¬¼, ì‚¬ë¬¼, í…ìŠ¤íŠ¸, ìŠ¬ë¼ì´ë“œ ë‚´ìš© ë“±)ì™€ ìƒí™©ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤. (í•œêµ­ì–´)" }
                  },
                  required: ["startTime", "endTime", "subtitle", "description"]
                }
              },
              keywords: { type: SchemaType.ARRAY, description: "ì˜ìƒ ì½˜í…ì¸ ì˜ í•µì‹¬ í‚¤ì›Œë“œ ëª©ë¡ì…ë‹ˆë‹¤. (í•œêµ­ì–´)", items: { type: SchemaType.STRING } }
            },
            required: ["transcript", "summary", "timeline", "keywords"]
          }
        }
      }); 

      const prompt = `Analyze this video deeply. Even if the video is in English, you MUST OUTPUT EVERYTHING IN KOREAN. Translate the context naturally.`;
      
      const result = await model.generateContent([
        { fileData: { mimeType: uploadedFile.mimeType, fileUri: uploadedFile.uri } },
        { text: prompt }
      ]);

      const output = JSON.parse(result.response.text());

      let vttPath = null;
      if (output.timeline && Array.isArray(output.timeline)) {
        const vttContent = `WEBVTT\n\n${output.timeline
          .map((item: any) => `${item.startTime} --> ${item.endTime}\n${item.subtitle}`)
          .join('\n\n')}`;
        
        const vttTempPath = path.join(os.tmpdir(), `${episodeId}.vtt`);
        fs.writeFileSync(vttTempPath, vttContent);
        
        vttPath = `episodes/${episodeId}/subtitles/${episodeId}.vtt`;
        
        await bucket.upload(vttTempPath, {
          destination: vttPath,
          metadata: { contentType: 'text/vtt' },
        });

        if (fs.existsSync(vttTempPath)) fs.unlinkSync(vttTempPath);
        console.log(`[${episodeId}] VTT subtitle file created.`);
      }

      const analysisJsonString = JSON.stringify(output);
      const afterData = (await docRef.get()).data() as EpisodeData;
      const courseDoc = await db.collection('courses').doc(afterData.courseId).get();
      if (!courseDoc.exists) throw new Error(`Course not found for episode ${episodeId}`);
      const classificationDoc = await db.collection('classifications').doc(courseDoc.data()!.classificationId).get();
      if (!classificationDoc.exists) throw new Error(`Classification not found for course ${courseDoc.id}`);
      const fieldId = classificationDoc.data()!.fieldId;
      
      const aiChunkData = {
          episodeId,
          courseId: afterData.courseId,
          classificationId: courseDoc.data()!.classificationId,
          fieldId,
          content: analysisJsonString,
          createdAt: admin.firestore.FieldValue.serverTimestamp(),
      };

      const batch = db.batch();
      
      batch.update(docRef, {
        aiProcessingStatus: "completed",
        aiModel: modelName,
        transcript: output.transcript || "",
        aiGeneratedContent: analysisJsonString,
        vttPath: vttPath,
        aiProcessingError: null,
        updatedAt: admin.firestore.FieldValue.serverTimestamp(),
      });

      const aiChunkRef = db.collection('episode_ai_chunks').doc(episodeId);
      batch.set(aiChunkRef, aiChunkData);

      await batch.commit();

      console.log(`[${episodeId}] AI analysis succeeded!`);

    } catch (error: any) {
      const detailedError = JSON.stringify(error, Object.getOwnPropertyNames(error), 2);
      console.error(`âŒ [${episodeId}] AI analysis failed. Detailed error:`, detailedError);
      await docRef.update({
        aiProcessingStatus: "failed",
        aiProcessingError: error.message || String(error)
      });
    } finally {
      if (fs.existsSync(tempFilePath)) { try { fs.unlinkSync(tempFilePath); } catch (e) {} }
      if (uploadedFile) { try { await localFileManager.deleteFile(uploadedFile.name); } catch (e) {} }
    }
}

// ==========================================
// [Trigger] íŒŒì¼ ì‚­ì œ í•¨ìˆ˜ (v2 onDocumentDeleted)
// ==========================================
export const deleteFilesOnEpisodeDelete = onDocumentDeleted("episodes/{episodeId}", async (event) => {
    const snap = event.data;
    if (!snap) return;

    const { episodeId } = event.params;
    const data = snap.data() as EpisodeData;
    if (!data) return;
    
    await bucket.deleteFiles({ prefix: `episodes/${episodeId}/` }).catch(() => {});
    
    const aiChunkRef = db.collection('episode_ai_chunks').doc(episodeId);
    await aiChunkRef.delete().catch(() => {});

    console.log(`[DELETE SUCCESS] Cleaned up files and AI chunk for deleted episode ${episodeId}`);
});

interface EpisodeData {
  filePath: string;
  courseId: string;
  aiProcessingStatus?: string;
  packagingStatus?: 'pending' | 'processing' | 'completed' | 'failed';
  packagingError?: string | null;
  defaultThumbnailPath?: string;
  customThumbnailPath?: string;
  vttPath?: string;
  [key: string]: any;
}